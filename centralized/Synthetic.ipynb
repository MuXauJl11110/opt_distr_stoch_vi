{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra: norm, opnorm, eigen\n",
    "using Plots \n",
    "using Pickle # for saving data. One can comment it\n",
    "\n",
    "include(\"problem_instances.jl\")\n",
    "using .Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean run\n",
    "\n",
    "\n",
    "| id  | function  | n  |   |   |\n",
    "|---|---|---|---|---|\n",
    "|probl_1| policeman_and_burglar_matrix  |  500 |   |   |\n",
    "|probl_2| nemirovski1  | 500  |   |   |\n",
    "|probl_3| nemirovski2   | 500  |   |   |\n",
    "\n",
    "The first problem is randomly generated. For the paper we used seed `sd=\"1\"`. Set `sd=\"false\"` otherwise. For the first run of code set `m, n, N` small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dimensions and problem instance\n",
    "m, n = 50, 50\n",
    "batch_sizes = [1, 3, 5, 10]\n",
    "\n",
    "probl = 1 # 1, 2 or 3\n",
    "sd = \"1\"\n",
    "\n",
    "\n",
    "if probl == 1\n",
    "    A = Problems.policeman_and_burglar_matrix(n; seed=sd)\n",
    "    filename = \"save/probl_1e\" \n",
    "elseif probl == 2\n",
    "    A = Problems.nemirovski1(n)\n",
    "    filename = \"save/probl_2e\" \n",
    "elseif probl == 3\n",
    "    A = Problems.nemirovski2(n, 2)\n",
    "    filename = \"save/probl_3e\"\n",
    "elseif probl == 4\n",
    "    A = Problems.randunif(m, n; seed=sd)\n",
    "    filename = \"save/probl_4e\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute different norms of A\n",
    "max_norm = maximum(abs.(A))\n",
    "l2_norm = norm(A, 2)\n",
    "sp_norm = opnorm(A) # L\n",
    "nnz = length(A[A .!= 0])\n",
    "print(\"Operator norm of A is $(round(sp_norm, digits=1)),\n",
    "Frobenius norm is $(round(l2_norm, digits=1)),\n",
    "max norm is $(round(max_norm, digits=1))\n",
    "nnz(A) is $nnz. Total elements in A: $(m*n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = ones(n)/n \n",
    "y0 = ones(m)/m\n",
    "\n",
    "z0 = [x0; y0]\n",
    "tol = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make quick plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr()\n",
    "\n",
    "# some hack to put markers less frequently. From https://github.com/JuliaPlots/Plots.jl/issues/2523#issuecomment-607090470\n",
    "# now their frequency is controled by parameter `step`\n",
    "\n",
    "@recipe function f(::Type{Val{:samplemarkers}}, x, y, z; step = 500)\n",
    "    n = length(y)\n",
    "    sx, sy = x[1:step:n], y[1:step:n]\n",
    "    # add an empty series with the correct type for legend markers\n",
    "    @series begin\n",
    "        seriestype := :path\n",
    "        markershape --> :auto\n",
    "        x := [Inf]\n",
    "        y := [Inf]\n",
    "    end\n",
    "    # add a series for the line\n",
    "    @series begin\n",
    "        primary := false # no legend entry\n",
    "        markershape := :none # ensure no markers\n",
    "        seriestype := :path\n",
    "        seriescolor := get(plotattributes, :seriescolor, :auto)\n",
    "        x := x\n",
    "        y := y\n",
    "    end\n",
    "    # return  a series for the sampled markers\n",
    "    primary := false\n",
    "    seriestype := :scatter\n",
    "    markershape --> :auto\n",
    "    x := sx\n",
    "    y := sy\n",
    "end\n",
    "### end of hack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set number of epochs `N` and run the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"algorithms.jl\")\n",
    "projection(x) = proj_simplex1(x)\n",
    "N = 10000 # max epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function for searching $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find γ that deliver the fastet convergency to the threshold\n",
    "function find_γ(method::Function, b::Int, γ_arr::Array{Float64, 1}, thrs::Float64=1e-5)\n",
    "    thrs_reached = false\n",
    "    γ_best = γ_arr[1]\n",
    "    res = method(b, γ_best)\n",
    "    ind = findfirst(res[1] .<= thrs)\n",
    "    iter_best = res[4][isnothing(ind) ? end : ind]\n",
    "    for γ in γ_arr[2:end]\n",
    "        res = method(b, γ)\n",
    "        ind = findfirst(res[1] .<= thrs)\n",
    "        if res[4][isnothing(ind) ? end : ind] < iter_best\n",
    "            iter_best = res[4][isnothing(ind) ? end : ind]\n",
    "            γ_best = γ\n",
    "        end\n",
    "    end\n",
    "    return γ_best\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function for drawing methods with different $\\gamma$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function draw_γ(method::Function, label::String, b::Int, γ_arr::Array{Float64, 1})\n",
    "    γ = γ_arr[1]\n",
    "    res = method(b, γ)\n",
    "    ind = res[1][1:min(size(res[1])[1], size(res[4])[1])] .> 0\n",
    "    display(plot(res[4][ind], res[1][ind], label=label*\" γ:$γ\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "    for γ in γ_arr[2:end]\n",
    "        IJulia.clear_output(true)\n",
    "        res = method(b, γ)\n",
    "        ind = res[1][1:min(size(res[1])[1], size(res[4])[1])] .> 0\n",
    "        display(plot!(res[4][ind], res[1][ind], label=label*\" γ:$γ\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function for drawing methods with different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function draw_b(method::Function, label::String, γ::Float64, b_arr::Array{Int, 1})\n",
    "    b = b_arr[1]\n",
    "    res = method(b, γ)\n",
    "    ind = res[1][1:min(size(res[1])[1], size(res[4])[1])] .> 0\n",
    "    display(plot(res[4][ind], res[1][ind], label=label*\" b:$b\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "    for b in b_arr[2:end]\n",
    "        IJulia.clear_output(true)\n",
    "        res = method(b, γ)\n",
    "        ind = res[1][1:min(size(res[1])[1], size(res[4])[1])] .> 0\n",
    "        display(plot!(res[4][ind], res[1][ind], label=label*\" b:$b\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic extragradient with variance reduction (loopless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_eg_loopless(b_eg_loopless::Int, γ_eg_loopless::Float64=0.99, theor::Bool=false)\n",
    "    K_eg_loopless = ceil(Int64, nnz/(m + n)/b_eg_loopless)\n",
    "    p_eg_loopless = 1.0 / K_eg_loopless\n",
    "    α_eg_loopless = 1 - p_eg_loopless\n",
    "    L_eg_loopless = sp_norm\n",
    "    \n",
    "    τ_eg_loopless = sqrt(1-α_eg_loopless)/L_eg_loopless * γ_eg_loopless\n",
    "    return stochExtraGradLoopless(A, projection, z0, τ_eg_loopless, α_eg_loopless, p_eg_loopless,\n",
    "        b_eg_loopless, N, distr=true, tol=tol)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_γ(compute_eg_loopless, 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_γ(compute_eg_loopless, \"EG-Loopless\", 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_b(compute_eg_loopless, \"EG-Loopless\", 0.4, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic extragradient with variance reduction (looped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_eg_looped(b_eg_looped::Int, γ_eg_looped::Float64=0.99, theor::Bool=false)\n",
    "    K_eg_looped = ceil(Int64, nnz/(m + n)/b_eg_looped)\n",
    "    p_eg_looped = 1.0 / K_eg_looped\n",
    "    α_eg_looped = 1 - p_eg_looped\n",
    "    L_eg_looped = sp_norm\n",
    "    \n",
    "    τ_eg_looped = sqrt(1-α_eg_looped)/L_eg_looped * γ_eg_looped\n",
    "    return stochExtraGradLooped(A, projection, z0, τ_eg_looped, α_eg_looped, K_eg_looped, b_eg_looped, N, \n",
    "        distr=true, tol=tol)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_γ(compute_eg_looped, 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_γ(compute_eg_looped, \"EG-Looped\", 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_b(compute_eg_looped, \"EG-Looped\", 0.4, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_algorithm2(b_algorithm2::Int, c_2::Float64=1.3, theor::Bool=false)\n",
    "    w0 = z0\n",
    "    L = l2_norm\n",
    "    γ_2 = min(1/16, b_algorithm2 / n)\n",
    "    p_2 = γ_2\n",
    "    α_2 = 1 / p_2\n",
    "    if theor\n",
    "        η_2 = c_2 * min(sqrt(α_2 * γ_2 * b_algorithm2) / 2 * L, 1 / (8 * L))\n",
    "    else\n",
    "        η_2 = c_2 / L\n",
    "    end\n",
    "    \n",
    "    return stochAlgorithm2(A, projection, z0, w0, α_2, γ_2, η_2, p_2, b_algorithm2, N, distr=true, tol=tol)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_γ(compute_algorithm2, 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_γ(compute_algorithm2, \"Algorithm2\", 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_b(compute_algorithm2, \"Algorithm2\", 0.1, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carmon et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_MPCarmon(b_mp_carmon::Int, step_mult::Float64=0.01, theor::Bool=false)\n",
    "    alpha_ = l2_norm * sqrt((m + n)/(2 * m * n) / b_mp_carmon)\n",
    "    η = alpha_ / (step_mult * l2_norm^2);\n",
    "    \n",
    "    return stochMPCarmon(A, projection, z0, alpha_, η, b_mp_carmon, N, distr=true, tol=tol)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_γ(compute_MPCarmon, 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_γ(compute_MPCarmon, \"MP-Car\", 1, [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_b(compute_MPCarmon, \"MP-Car\", 0.0001, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_b(b::Int, γ_arr::Array{Float64, 1}, thrs::Float64=1e-5)\n",
    "    methods = [compute_eg_loopless, compute_eg_looped, compute_algorithm2, compute_MPCarmon]\n",
    "    #γ_arr = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.4, 0.5, 0.9, 0.99, 1.0]\n",
    "    labels = [\"EG-Loopless b:$b\", \"EG-Looped b:$b\", \"Algorithm2 b:$b\", \"MP-Car b:$b\"]\n",
    "    appendix = [\"EG-Loopless\", \"EG-Looped\", \"Algorithm2\", \"MPC\"]\n",
    "    for i in 1:length(methods)\n",
    "        IJulia.clear_output(true)\n",
    "        method = methods[i]\n",
    "        label = labels[i]\n",
    "        #γ = find_γ(method, b, γ_arr, thrs)\n",
    "        γ = γ_arr[i]\n",
    "        res = method(b, γ)\n",
    "        ind = res[1][1:min(size(res[1])[1], size(res[4])[1])] .> 0\n",
    "        if i == 1\n",
    "            display(plot(res[4][ind], res[1][ind], label=label*\" γ:$γ\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "        else\n",
    "            display(plot!(res[4][ind], res[1][ind], label=label*\" γ:$γ\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "        end\n",
    "        Pickle.store(filename*\"b$b\"*appendix[i], res)\n",
    "    end\n",
    "    for i in 1:length(methods)\n",
    "        IJulia.clear_output(true)\n",
    "        method = methods[i]\n",
    "        label = labels[i]\n",
    "        γ = 1.\n",
    "        res = method(b, γ, true)\n",
    "        ind = res[1][1:min(size(res[1])[1], size(res[4])[1])] .> 0\n",
    "        display(plot!(res[4][ind], res[1][ind], label=label*\" γ:$γ\", linewidth=2, marker=:utriangle, seriestype=:samplemarkers, step=45, yaxis=:log))\n",
    "        Pickle.store(filename*\"b$b\"*appendix[i]*\"orig\", res)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for the first problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_probl1 = Dict(\n",
    "1 => [1.0, 1.0, 0.1, 0.0001],\n",
    "3 => [1.0, 1.0, 0.5, 0.0001],\n",
    "5 => [1.0, 1.0, 0.5, 0.0001],\n",
    "10 => [1.0, 1.0, 0.5, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for the second problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_probl2 = Dict(\n",
    "1 => [1.0, 0.9, 0.99, 0.001],\n",
    "3 => [1.0, 1.0, 1.0, 0.0001],\n",
    "5 => [1.0, 1.0, 1.0, 0.01],\n",
    "10 => [1.0, 0.9, 1.0, 0.0001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for the third problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_probl3 = Dict(\n",
    "1 => [0.99, 0.9, 0.3, 0.0001],\n",
    "3 => [0.99, 0.9, 0.99, 0.001],\n",
    "5 => [1.0, 1.0, 0.4, 0.0001],\n",
    "10 => [0.99, 1.0, 0.99, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing is not important here, since we compare algorithms' performance with respect to arithmetic operations. And of course our implmentation is not so good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
